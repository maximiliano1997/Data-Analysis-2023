{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5bdaec30",
   "metadata": {},
   "source": [
    "### Partes 1 y 2: \n",
    "\n",
    "\n",
    "##### (Part1) Getting Started with Data Analysis - Installation and Loading Data\n",
    "##### (Part2) - DataFrame and Series Basics.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54ae4420",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3951378164.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[1], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    import pandas as pdimport pandas as pd\u001b[0m\n\u001b[1;37m                              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pdimport pandas as pd\n",
    "\n",
    "df = pd.read_csv('../data/survey_results_public.csv')\n",
    "schema_df = pd.read_csv('../data/survey_results_schema.csv')\n",
    "\n",
    "df\n",
    "\n",
    "schema_df\n",
    "\n",
    "df.shape\n",
    "\n",
    "df.info()\n",
    "\n",
    "pd.set_option('display.max_columns', 200)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.min_rows', 100)\n",
    "pd.set_option('display.expand_frame_repr', True)\n",
    "\n",
    "df\n",
    "\n",
    "df.tail(10)\n",
    "\n",
    "df.head(5)\n",
    "\n",
    "df.iloc[1:,2]\n",
    "\n",
    "df.loc[10, ['CompTotal','CompFreq','Currency','Employment']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f7e9cc",
   "metadata": {},
   "source": [
    "# Partes 3 y 4: \n",
    "\n",
    "##### (3) Indexes: How to Set, Reset, and Use Indexes\n",
    "##### (4)Filtering: Using Conditionals to Filter Rows and Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf6e3119",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of ['ResponseId'] are in the columns\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 37\u001b[0m\n\u001b[0;32m     33\u001b[0m pd\u001b[38;5;241m.\u001b[39mset_option(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdisplay.max_rows\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;241m73\u001b[39m)\n\u001b[0;32m     35\u001b[0m dfs\u001b[38;5;241m.\u001b[39mhead()\n\u001b[1;32m---> 37\u001b[0m \u001b[43mdfs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_index\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mResponseId\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m schema_dfs\n\u001b[0;32m     41\u001b[0m schema_dfs\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEmployment\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:5869\u001b[0m, in \u001b[0;36mDataFrame.set_index\u001b[1;34m(self, keys, drop, append, inplace, verify_integrity)\u001b[0m\n\u001b[0;32m   5866\u001b[0m                 missing\u001b[38;5;241m.\u001b[39mappend(col)\n\u001b[0;32m   5868\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m missing:\n\u001b[1;32m-> 5869\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmissing\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m are in the columns\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   5871\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[0;32m   5872\u001b[0m     frame \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of ['ResponseId'] are in the columns\""
     ]
    }
   ],
   "source": [
    "## (3) Indexes: How to Set, Reset, and Use Indexes\n",
    "\n",
    "people = {\n",
    "\"first\": [\"Corey\",\"Jane\",\"Jhon\"],\n",
    "\"last\": [\"Schafer\",\"Doe\",\"Doe\"],\n",
    "\"email\": [\"CoreyMSchager@gmail.com\",\"loco@gamil.com\",\"lineal@gmail.com\"],\n",
    "}\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(people)\n",
    "\n",
    "df\n",
    "\n",
    "df['email']\n",
    "\n",
    "df.set_index('email', inplace=True)\n",
    "\n",
    "df\n",
    "\n",
    "df.index\n",
    "\n",
    "df.loc['lineal@gmail.com', 'last']\n",
    "\n",
    "df.reset_index(inplace=True)\n",
    "\n",
    "# Working with stackoverflow data \n",
    "\n",
    "dfs = pd.read_csv('../data/survey_results_public.csv', index_col='ResponseId')\n",
    "schema_dfs = pd.read_csv('../data/survey_results_schema.csv', index_col='qname')\n",
    "\n",
    "pd.set_option('display.max_columns',79)\n",
    "pd.set_option('display.max_rows',73)\n",
    "\n",
    "dfs.head()\n",
    "\n",
    "dfs.set_index('ResponseId', inplace=True)\n",
    "\n",
    "schema_dfs\n",
    "\n",
    "schema_dfs.loc['Employment', 'question']\n",
    "\n",
    "schema_dfs.sort_index()\n",
    "\n",
    "# ------------------------------END--------------------------------\n",
    "\n",
    "## (4)Filtering: Using Conditionals to Filter Rows and Columns\n",
    "\n",
    "df\n",
    "\n",
    "filt = (df['last'] == 'Doe') & (df['first'] == 'Jane')\n",
    "\n",
    "df[filt]\n",
    "\n",
    "df.loc[-filt, 'email']\n",
    "\n",
    "# Working with Stackoverflow Data \n",
    "\n",
    "dfs.head()\n",
    "\n",
    "high_salary = (dfs['CompTotal'] > 200000)\n",
    "\n",
    "dfs.loc[high_salary, ['CompTotal', 'CompFreq', 'Currency', 'Country', 'LanguageHaveWorkedWith']]\n",
    "\n",
    "countries = ['Uruguay','Argentina','Paraguay']\n",
    "search = (dfs['Country'].isin(countries))\n",
    "\n",
    "dfs.loc[search, ['Country' ,'CompTotal', 'Currency', 'CompFreq', 'LanguageHaveWorkedWith']]\n",
    "\n",
    "pd.set_option('display.max_columns', 70)\n",
    "pd.set_option('display.max_rows', 600)\n",
    "pd.set_option('display.min_rows', 600)\n",
    "\n",
    "containFilter = dfs['LanguageHaveWorkedWith'].str.contains('Python', na=False)\n",
    "\n",
    "containFilter\n",
    "\n",
    "dfs.loc[containFilter, 'LanguageHaveWorkedWith']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f1beca",
   "metadata": {},
   "source": [
    "# Partes 5 y 6: \n",
    "\n",
    "##### (5): Updating Rows and Columns - Modifying Data Within DataFrames\n",
    "##### (Part 6) Add or Remove Rows and Columns From DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18c96620",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_3060\\4109885559.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[filt]['last'] = 'Smith'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>email</th>\n",
       "      <th>Full_Name</th>\n",
       "      <th>first</th>\n",
       "      <th>last</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>coreymschager@gmail.com</td>\n",
       "      <td>Lionel Schafer</td>\n",
       "      <td>Lionel</td>\n",
       "      <td>Schafer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lineal@gmail.com</td>\n",
       "      <td>Imanol Pnachito</td>\n",
       "      <td>Imanol</td>\n",
       "      <td>Pnachito</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     email        Full_Name   first      last\n",
       "0  coreymschager@gmail.com   Lionel Schafer  Lionel   Schafer\n",
       "2         lineal@gmail.com  Imanol Pnachito  Imanol  Pnachito"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (5): Updating Rows and Columns - Modifying Data Within DataFrames\n",
    "\n",
    "#### In this Python Programming, we will be learning how to modify the data within our DataFrames. We will use some of the filtering techniques we learned in the last video to update values conditionally, and we will also be learning how to use the apply, map, and applymap method. Let's get started...\n",
    "\n",
    "people = {\n",
    "\"first\": [\"Corey\",\"Jane\",\"Jhon\"],\n",
    "\"last\": [\"Schafer\",\"Doe\",\"Doe\"],\n",
    "\"email\": [\"CoreyMSchager@gmail.com\",\"loco@gamil.com\",\"lineal@gmail.com\"],\n",
    "}\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(people)\n",
    "\n",
    "df\n",
    "\n",
    "df.columns\n",
    "\n",
    "df.columns = ['first_name', 'last_name', 'email']\n",
    "\n",
    "df\n",
    "\n",
    "df.columns = [x.lower() for x in df.columns]\n",
    "df\n",
    "\n",
    "df.columns = df.columns.str.replace(' ', \"_\")\n",
    "df\n",
    "\n",
    "df.rename(columns={'first_name': 'first', 'last_name': 'last'}, inplace=True)\n",
    "\n",
    "df.loc[2] = ['Imanol','Aguer','imanolaguer1@gmail.com']\n",
    "df\n",
    "\n",
    "df.loc[2, ['last','email']] = ['Doe','lineal@gmail.com']\n",
    "df\n",
    "\n",
    "# This is a Common error when try to change data\n",
    "filt = (df['email'] == 'lineal@gmail.com')\n",
    "df[filt]['last'] = 'Smith'\n",
    "\n",
    "# Asi se soluciona... con La manera correcta de modificar data en el DataFrame\n",
    "filt = (df['email'] == 'lineal@gmail.com')\n",
    "df.loc[filt, 'last'] = ['Pnachito']\n",
    "\n",
    "df['email'] = df['email'].str.lower()\n",
    "df\n",
    "\n",
    "#### Recuerda estos metodos\n",
    "##### 1- apply 2. map 3. applymap 4.replace\n",
    "\n",
    "## apply method \n",
    "\n",
    "df['email'].apply(len)\n",
    "\n",
    "def update_email(email):\n",
    "    return email.upper()\n",
    "\n",
    "df['email'] = df['email'].apply(update_email)\n",
    "# df\n",
    "\n",
    "df['email'] = df['email'].apply(lambda x: x.lower()) # Esta es una funcion Lambda\n",
    "df\n",
    "\n",
    "df.apply(len)\n",
    "\n",
    "df.apply(pd.Series.min)\n",
    "\n",
    "### applymap method\n",
    "\n",
    "df.applymap(len) # <---- te dara Len() de cada elemento individual del DataFrame\n",
    "\n",
    "df.applymap(str.upper)\n",
    "\n",
    "### map method \n",
    "\n",
    "df['first'].map({'Corey': 'Lionel','Jane': 'Cristiano'}) #atencion: no pone los cambios pernanentes\n",
    "\n",
    "df['first'] = df['first'].replace({'Corey': 'Lionel', 'Jane':'Cristiano'}) #Atencion: aqui si los cambios quedan\n",
    "df\n",
    "\n",
    "# Working with Stackoverflow Data \n",
    "\n",
    "dfs = pd.read_csv('../data/survey_results_public.csv')\n",
    "schema_dfs = pd.read_csv('../data/survey_results_schema.csv')\n",
    "\n",
    "dfs.head(20)\n",
    "\n",
    "dfs['Currency']\n",
    "\n",
    "dfs.rename(columns={'Currency': 'LocalCurrency'}, inplace=True)\n",
    "\n",
    "dfs['LocalCurrency']\n",
    "\n",
    "dfs['SurveyEase']\n",
    "\n",
    "dfs['SurveyEase'] = dfs['SurveyEase'].map({'Easy': 'Facil', 'Difficult': 'Dificil', 'Neither easy nor difficult':'ni pedos'})\n",
    "# A veces es conveniente usar metodo .replace en vez de .map\n",
    "\n",
    "dfs.head()\n",
    "\n",
    "# (Part 6) Add or Remove Rows and Columns From DataFrames \n",
    "\n",
    "\n",
    "### This is how we add columns to our DataFrame\n",
    "\n",
    "df['first'] + \" \" + df['last']\n",
    "\n",
    "df[\"Full_Name\"] = df['first'] + \" \" + df['last'] # <--- Created a new column\n",
    "\n",
    "df\n",
    "\n",
    "### This is how we remove columns to our DataFrame \n",
    "\n",
    "df.drop(columns=['first', 'last'], inplace=True) # <--- Borra las columnas first y last\n",
    "df\n",
    "# Hey, Imanol other thins!\n",
    "# You can simply delete columns by using \"del\" function.\n",
    "# For example: del df['full_name']\n",
    "\n",
    "df['Full_Name'].str.split(\" \", expand=True)\n",
    "\n",
    "df[['first','last']] = df['Full_Name'].str.split(\" \", expand=True)\n",
    "\n",
    "df\n",
    "\n",
    "# df.drop(columns=['Full_Name'])\n",
    "\n",
    "# df.append({'first': 'Tony'}) # Append was deprecated in new version of pandas, now are used concat\n",
    "df = pd.concat([df, pd.DataFrame([{'first': 'Tony'}])]) # <-- Add single row / ignore index\n",
    "\n",
    "df\n",
    "\n",
    "## Second DataFrame... people2\n",
    "\n",
    "people2 = {\n",
    "    \"first\": [\"George\", \"Martin\"],\n",
    "    \"last\": [\"Hotz\", \"Shkreli\"],\n",
    "    \"email\": [\"Hotz@gmail.com\", \"Shkreli@gamil.com\"],\n",
    "}\n",
    "df2 = pd.DataFrame(people2)\n",
    "df2\n",
    "\n",
    "df = pd.concat([df,df2], ignore_index=True, sort=False) # <--- This replaces the method append of min 11:30\n",
    "\n",
    "df\n",
    "\n",
    "df.drop(index=(3), inplace=True) # <--- remover un row individual\n",
    "df\n",
    "\n",
    "df.drop(index=[4,5], inplace=True) # <--- remover un grupo de rows\n",
    "df\n",
    "\n",
    "df\n",
    "\n",
    "df.drop(index=df[df['last'] == 'Doe'].index, inplace=True) # <--- Remover rows con un condicional\n",
    "# Tambien recuerda que puedes almacenar el condicional en una variable y solo pasar la variable al drop index=[filt]\n",
    "filt = df['last'] == 'Doe' # <-- Usando\n",
    "\n",
    "df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "776dfa63",
   "metadata": {},
   "source": [
    "# Partes 7 y 8: \n",
    "\n",
    "##### (Part 7): Sorting Data\n",
    "##### (Part 8) - Grouping and Aggregating - Analyzing and Exploring Your Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07fb78fe",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'SeriesGroupBy' object has no attribute 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 84\u001b[0m\n\u001b[0;32m     80\u001b[0m country_grp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCompTotal\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmedian()\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mArgentina\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     82\u001b[0m country_grp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCompTotal\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39magg([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmedian\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCanada\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m---> 84\u001b[0m \u001b[43mcountry_grp\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mLanguageHaveWorkedWith\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstr\u001b[49m\u001b[38;5;241m.\u001b[39mcontains(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPython\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39msum()\n\u001b[0;32m     86\u001b[0m country_grp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLanguageHaveWorkedWith\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\n\u001b[0;32m     87\u001b[0m    \u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mcontains(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPython\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39msum())\n\u001b[0;32m     89\u001b[0m country_respondents \u001b[38;5;241m=\u001b[39m dfs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCountry\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalue_counts()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:952\u001b[0m, in \u001b[0;36mGroupBy.__getattr__\u001b[1;34m(self, attr)\u001b[0m\n\u001b[0;32m    949\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj:\n\u001b[0;32m    950\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[attr]\n\u001b[1;32m--> 952\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[0;32m    953\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    954\u001b[0m )\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'SeriesGroupBy' object has no attribute 'str'"
     ]
    }
   ],
   "source": [
    "## (Part 7): Sorting Data\n",
    "\n",
    "people = {\n",
    "    \"first\": [\"Corey\", \"Jane\", \"Jhon\",\"Adam\"],\n",
    "    \"last\": [\"Schafer\", \"Doe\", \"Doe\", \"Doe\"],\n",
    "    \"email\": [\"CoreyMSchager@gmail.com\", \"loco@gamil.com\", \"lineal@gmail.com\", \"A@email.com\"],\n",
    "}\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(people)\n",
    "df\n",
    "\n",
    "df.sort_values(by='last', ascending=False)\n",
    "\n",
    "df.sort_values(by=['last','first'], ascending=False)\n",
    "\n",
    "df.sort_values(by=['last','first'], ascending=[False, True], inplace=True)\n",
    "df\n",
    "\n",
    "\n",
    "df.sort_index()\n",
    "\n",
    "df['last'].sort_values()\n",
    "\n",
    "## Working With StakOverflow Data\n",
    "\n",
    "dfs = pd.read_csv('../data/survey_results_public.csv')\n",
    "schema_dfs = pd.read_csv('../data/survey_results_schema.csv')\n",
    "\n",
    "pd.set_option('display.max_columns', 79)\n",
    "pd.set_option('display.max_rows', 50)\n",
    "pd.set_option('display.min_rows', 50)\n",
    "dfs.head()\n",
    "\n",
    "dfs.sort_values(by=['Country', 'Currency', 'CompTotal'], ascending=[True, False, False], inplace=True)\n",
    "\n",
    "dfs[['Country', 'Currency', 'CompTotal']].head(150)\n",
    "\n",
    "\n",
    "dfs['CompTotal'].nlargest(10)\n",
    "\n",
    "dfs.nlargest(10, 'CompTotal')\n",
    "\n",
    "dfs.nsmallest(10, 'CompTotal')\n",
    "\n",
    "## (Part 8) - Grouping and Aggregating - Analyzing and Exploring Your Data\n",
    "\n",
    "dfs.head()\n",
    "\n",
    "dfs['CompTotal'].head(15)\n",
    "\n",
    "dfs['CompTotal'].median()\n",
    "\n",
    "dfs.describe()\n",
    "\n",
    "dfs['CompTotal'].count()\n",
    "\n",
    "dfs['SOAccount']\n",
    "\n",
    "dfs['SOAccount'].value_counts()\n",
    "\n",
    "dfs['Sexuality']\n",
    "\n",
    "schema_dfs.loc[47]\n",
    "\n",
    "dfs['Sexuality'].value_counts(normalize=True)\n",
    "\n",
    "dfs['Country'].value_counts()\n",
    "\n",
    "country_grp = dfs.groupby(dfs['Country'])\n",
    "\n",
    "country_grp.get_group('Argentina')\n",
    "\n",
    "filt = dfs['Country'] == 'Argentina'\n",
    "dfs.loc[filt]['Sexuality'].value_counts()\n",
    "\n",
    "country_grp['Sexuality'].value_counts().loc['Argentina']\n",
    "\n",
    "country_grp['CompTotal'].median().loc['Argentina']\n",
    "\n",
    "country_grp['CompTotal'].agg(['median','mean']).loc['Canada']\n",
    "\n",
    "country_grp['LanguageHaveWorkedWith'].str.contains('Python').sum()\n",
    "\n",
    "country_grp['LanguageHaveWorkedWith'].apply(\n",
    "   lambda x: x.str.contains('Python').sum())\n",
    "\n",
    "country_respondents = dfs['Country'].value_counts()\n",
    "country_respondents\n",
    "\n",
    "country_uses_python = country_grp['LanguageHaveWorkedWith'].apply(lambda x: x.str.contains('Python').sum())\n",
    "country_uses_python\n",
    "\n",
    "python_df = pd.concat([country_respondents, country_uses_python], axis='columns', sort=False)\n",
    "python_df\n",
    "\n",
    "python_df.rename(columns={'count':'cantidadRespondieron', 'LanguageHaveWorkedWith':'LosQueSabenPyhon'}, inplace=True)\n",
    "\n",
    "python_df\n",
    "\n",
    "python_df['PerKnowPython'] = (python_df['LosQueSabenPyhon'] / python_df['cantidadRespondieron']) * 100\n",
    "\n",
    "python_df\n",
    "\n",
    "python_df.sort_values(by='PerKnowPython', ascending=False, inplace=True)\n",
    "\n",
    "python_df.head(50)\n",
    "\n",
    "python_df.loc['Argentina']\n",
    "\n",
    "# --------------- END --------------- \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d945711e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
